# -*- coding: utf-8 -*-
"""Chatboy finance backend.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IDqSDxI3OD1JK_38e1PUKLMgkRDHtcV_
"""

!pip install google-generativeai yfinance yahooquery python-dateutil pandas requests pycountry numpy
!pip install xgboost imbalanced-learn scikit-learn prophet matplotlib

"""Prueba 2"""

!python codigo_mamalon.py

# =========================
# 0) Instalación de librerías (solo Colab/Jupyter)
# =========================
!pip install -q google-generativeai yfinance yahooquery python-dateutil pandas requests pycountry numpy \
                 xgboost imbalanced-learn scikit-learn prophet matplotlib

# =========================
# 1) CLAVE DE API COMO VARIABLE DE ENTORNO (OPCIÓN 1)
# =========================
import os
os.environ["GEMINI_API_KEY"] = "AIzaSyBhC9LDJdkVUCtWQKgDUK-yAVSHXl6Axyg"  # <-- tu clave aquí


# =========================
# 2) IMPORTS
# =========================
import sys
import re
import time
import unicodedata
from datetime import date
from dateutil.relativedelta import relativedelta

import requests
import pycountry
import numpy as np
import pandas as pd
import yfinance as yf
from yahooquery import search as yq_search
from yahooquery import Ticker as yq_Ticker
import google.generativeai as genai

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from imblearn.over_sampling import SMOTE
import xgboost as xgb

import matplotlib
matplotlib.use("Agg")  # seguro para entornos sin display
import matplotlib.pyplot as plt
from prophet import Prophet
# En Colab
from google.colab import drive
drive.mount('/content/drive')




# =========================
# 3) CONFIG
# =========================
DEFAULT_MODEL = "gemini-1.5-flash"  # o "gemini-1.5-pro"

# Configurar Gemini desde la variable de entorno
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    raise RuntimeError("Falta GEMINI_API_KEY. Configura os.environ['GEMINI_API_KEY'] antes de continuar.")
genai.configure(api_key=api_key)
def run_codigo_mamalon_subprocess(path: str = "/content/codigo_mamalon.py") -> bool:
    """
    Ejecuta /content/codigo_mamalon.py en un PROCESO APARTE.
    No rompe el proceso principal si el script tiene errores de indentación o runtime.
    Devuelve True si se intentó ejecutar (exista o no error), False si no encontró el archivo.
    """
    import os, subprocess

    if not os.path.isfile(path):
        print(f"[DEBUG] codigo_mamalon.py no encontrado en: {path}")
        return False

    print(f"[DEBUG] Ejecutando codigo_mamalon.py vía subprocess: {path}")
    proc = subprocess.run(
        ["python", "-u", path],
        capture_output=True,
        text=True
    )
    # Log útiles para ver qué pasó dentro del script
    print("==== codigo_mamalon.py :: STDOUT ====\n", proc.stdout)
    print("==== codigo_mamalon.py :: STDERR ====\n", proc.stderr)
    print(f"[DEBUG] codigo_mamalon.py returncode: {proc.returncode}")

    # Aunque haya errores (returncode != 0), los artefactos creados antes del error quedan.
    return True




# =========================
# 4) PARSING DE PROMPTS
# =========================
MESES_RE = re.compile(r"(?:últimos|ultimos|de los|por|durante)?\s*(\d+)\s*(mes(?:es)?)", re.IGNORECASE)
def run_codigo_mamalon_subprocess(path: str = "/content/codigo_mamalon.py") -> bool:
    """
    Ejecuta /content/codigo_mamalon.py en un PROCESO APARTE.
    No rompe el proceso principal si el script tiene errores.
    Devuelve True si se intentó ejecutar (independientemente del returncode),
    False si no encontró el archivo.
    """
    import os, subprocess

    if not os.path.isfile(path):
        print(f"[DEBUG] codigo_mamalon.py no encontrado en: {path}")
        return False

    print(f"[DEBUG] Ejecutando codigo_mamalon.py vía subprocess: {path}")
    proc = subprocess.run(["python", "-u", path], capture_output=True, text=True)
    print("==== codigo_mamalon.py :: STDOUT ====\n", proc.stdout)
    print("==== codigo_mamalon.py :: STDERR ====\n", proc.stderr)
    print(f"[DEBUG] codigo_mamalon.py returncode: {proc.returncode}")
    return True
def normalize_ohlcv(df: pd.DataFrame, ticker: str | None = None) -> pd.DataFrame:
    """
    Devuelve un DF con columnas estándar: Open, High, Low, Close, Volume,
    sin importar si vienen como MultiIndex (('Close','AMZN')) o como strings raros.
    """
    if df is None or df.empty:
        return df

    out = df.copy()

    # Si columnas son MultiIndex, intenta quedarte con el nivel del ticker
    if isinstance(out.columns, pd.MultiIndex):
        try:
            if ticker and ticker in out.columns.get_level_values(-1):
                out = out.xs(key=ticker, level=-1, axis=1, drop_level=True)
            else:
                # si solo hay un ticker, elimina el último nivel
                if len(out.columns.levels[-1]) == 1:
                    out = out.droplevel(-1, axis=1)
                else:
                    # si hay varios y no diste ticker, toma el primero
                    first_tk = out.columns.levels[-1][0]
                    out = out.xs(key=first_tk, level=-1, axis=1, drop_level=True)
        except Exception:
            out.columns = [str(c) for c in out.columns]

    # Mapear por pattern insensible a caso
    cols_lower = {str(c).lower(): c for c in out.columns}
    target_map = {}
    for tgt, key in [("Open","open"),("High","high"),("Low","low"),("Close","close"),("Volume","volume")]:
        cand = [orig for low, orig in cols_lower.items() if key in low]
        if cand:
            target_map[tgt] = cand[0]

    std = pd.DataFrame(index=out.index)
    for tgt in ["Open","High","Low","Close","Volume"]:
        if tgt in target_map:
            std[tgt] = out[target_map[tgt]]

    return std

def extract_company_and_months(text: str):
    """
    Extrae (empresa, meses) de un prompt en español. (heurístico)
    """
    m = MESES_RE.search(text)
    months = int(m.group(1)) if m else None

    m2 = re.search(r"(?:de|sobre)\s+([A-Za-z0-9&\-\.\s]+?)(?:\s+(?:de los|últimos|ultimos|por|durante)\b|$)", text, re.IGNORECASE)
    if m2:
        empresa = m2.group(1).strip(" .")
    else:
        limpio = re.sub(r"(dame|quiero|necesito|datos|financieros|precios|históricos|historicos|de|los|la|empresa|últimos|ultimos|por|durante|mes(?:es)?)",
                        " ", text, flags=re.IGNORECASE)
        empresa = re.sub(r"\s+", " ", limpio).strip() or None

    return empresa, months


# =========================
# 5) RESOLVER TICKER (yahooquery)
# =========================
def resolve_ticker(company_query: str):
    """
    Busca el símbolo priorizando EQUITY en bolsas mayores.
    """
    try:
        res = yq_search(company_query)
        quotes = (res or {}).get("quotes", []) if isinstance(res, dict) else []
        if not quotes:
            return None, None

        major_exchanges = {"NMS","NAS","NGM","NCM","NYQ","NYE"}  # Nasdaq/NYSE variantes

        def quality(q):
            qt = q.get("quoteType")
            exch = q.get("exchange")
            score = q.get("score", 0.0) or 0.0
            has_short = 1 if q.get("shortname") else 0
            return (
                1 if qt == "EQUITY" else 0,
                1 if exch in major_exchanges else 0,
                score,
                has_short
            )

        equities = [q for q in quotes if q.get("symbol")]
        equities.sort(key=quality, reverse=True)
        top = equities[0]
        name = top.get("shortname") or top.get("longname") or top.get("name") or top.get("symbol")
        return top["symbol"], name
    except Exception:
        return None, None


# =========================
# 6) DESCARGA E IMPUTACIÓN
# =========================
def download_prices(symbol: str, months: int, interval="1d"):
    end = date.today()
    start = end - relativedelta(months=months)
    df = yf.download(symbol, start=start.isoformat(), end=end.isoformat(),
                     interval=interval, auto_adjust=True, progress=False)
    return df, start, end

def impute_nans_prices(df: pd.DataFrame):
    """
    Imputa NaN en columnas numéricas (interpolate time -> ffill/bfill)
    """
    if df is None or df.empty:
        return df, {"nan_totales_antes": 0, "nan_totales_despues": 0, "columnas_numericas": []}

    out = df.copy()
    try:
        out.index = pd.to_datetime(out.index, errors="coerce")
    except Exception:
        pass
    out = out.sort_index()
    out = out[~out.index.isna()]

    nan_before = int(out.isna().sum().sum())

    out.columns = list(map(str, out.columns))
    num_cols = out.select_dtypes(include=[np.number]).columns
    if len(num_cols) > 0:
        try:
            out[num_cols] = out[num_cols].interpolate(method="time", limit_direction="both")
        except Exception:
            out[num_cols] = out[num_cols].interpolate(limit_direction="both")
        out[num_cols] = out[num_cols].ffill().bfill()

    nan_after = int(out.isna().sum().sum())
    report = {
        "nan_totales_antes": nan_before,
        "nan_totales_despues": nan_after,
        "columnas_numericas": list(map(str, num_cols)),
    }
    return out, report


# =========================
# 7) GEMINI WRAPPER
# =========================
def make_model():
    return genai.GenerativeModel(DEFAULT_MODEL)

def answer_with_llm(chat, user_text):
    resp = chat.send_message(user_text)
    return (resp.text or "").strip()


# =========================
# 8) PERFIL PAÍS + BANCO MUNDIAL
# =========================
def get_company_country(symbol: str) -> str | None:
    try:
        t = yq_Ticker(symbol)
        prof = t.asset_profile
        if isinstance(prof, dict) and symbol in prof:
            country = prof[symbol].get("country")
            if country:
                return country
    except Exception:
        pass
    return None

def country_to_iso2(country_name: str) -> str | None:
    try:
        m = pycountry.countries.search_fuzzy(country_name)
        if m and len(m) > 0:
            return m[0].alpha_2.upper()
    except Exception:
        pass
    return None

WB_BASE = "https://api.worldbank.org/v2/country/{cc}/indicator/{ind}?format=json&per_page=60"

def wb_latest_two(cc_iso2: str, indicator: str, retries: int = 3, backoff: float = 1.5):
    url = WB_BASE.format(cc=cc_iso2, ind=indicator)
    for attempt in range(retries):
        try:
            r = requests.get(url, timeout=20)
            r.raise_for_status()
            data = r.json()
            if not isinstance(data, list) or len(data) < 2 or not isinstance(data[1], list):
                return None, None, None, None
            series = data[1]
            vals = [(e.get("value"), e.get("date")) for e in series if e.get("value") is not None and e.get("date")]
            if not vals:
                return None, None, None, None
            vals.sort(key=lambda x: int(x[1]), reverse=True)
            v0, y0 = vals[0]
            v1, y1 = (vals[1] if len(vals) > 1 else (None, None))
            return float(v0), int(y0), (float(v1) if v1 is not None else None), (int(y1) if y1 is not None else None)
        except Exception:
            if attempt == retries - 1:
                return None, None, None, None
            time.sleep(backoff ** attempt)

def clamp01(x: float) -> float:
    return max(0.0, min(1.0, x))

def compute_macro_features(country_name: str):
    iso2 = country_to_iso2(country_name or "")
    if not iso2:
        raise ValueError(f"No pude mapear el país a ISO2: {country_name!r}")

    infl0, yi0, infl1, yi1 = wb_latest_two(iso2, "FP.CPI.TOTL.ZG")
    d_infl = (infl0 - infl1) if (infl0 is not None and infl1 is not None) else None

    gdp0, yg0, gdp1, yg1 = wb_latest_two(iso2, "NY.GDP.MKTP.KD.ZG")
    d_gdp = (gdp0 - gdp1) if (gdp0 is not None and gdp1 is not None) else None

    unemp0, yu0, unemp1, yu1 = wb_latest_two(iso2, "SL.UEM.TOTL.ZS")
    d_unemp = (unemp0 - unemp1) if (unemp0 is not None and unemp1 is not None) else None

    w_infl, w_gdp, w_unemp = 0.40, 0.35, 0.25

    if infl0 is not None:
        s_infl = clamp01(1.0 - abs(infl0 - 2.0)/8.0)
        if d_infl is not None:
            s_infl = clamp01(s_infl + (0.25 if d_infl < 0 else (-0.25 if d_infl > 0 else 0.0)))
    else:
        s_infl = 0.5

    if gdp0 is not None:
        s_gdp = clamp01((gdp0)/8.0)
        if d_gdp is not None:
            s_gdp = clamp01(s_gdp + (0.20 if d_gdp > 0 else (-0.10 if d_gdp < 0 else 0.0)))
    else:
        s_gdp = 0.5

    if unemp0 is not None:
        s_unemp = clamp01(1.0 - (unemp0/15.0))
        if d_unemp is not None:
            s_unemp = clamp01(s_unemp + (0.20 if d_unemp < 0 else (-0.10 if d_unemp > 0 else 0.0)))
    else:
        s_unemp = 0.5

    macro_score = clamp01(w_infl*s_infl + w_gdp*s_gdp + w_unemp*s_unemp)

    vec = np.array([
        (infl0 if infl0 is not None else np.nan),
        (d_infl if d_infl is not None else np.nan),
        (gdp0 if gdp0 is not None else np.nan),
        (d_gdp if d_gdp is not None else np.nan),
        (unemp0 if unemp0 is not None else np.nan),
        (d_unemp if d_unemp is not None else np.nan),
        macro_score
    ], dtype=float)

    meta = {
        "country": country_name,
        "iso2": iso2,
        "inflation_yoy": infl0, "infl_year": yi0, "delta_inflation": d_infl,
        "gdp_real_growth": gdp0, "gdp_year": yg0, "delta_gdp_growth": d_gdp,
        "unemployment": unemp0, "unemp_year": yu0, "delta_unemployment": d_unemp,
        "score_infl": s_infl, "score_gdp": s_gdp, "score_unemp": s_unemp,
        "macro_score": macro_score
    }
    return meta, vec


# =========================
# 9) UTILS DE ARCHIVOS
# =========================
def slugify(s: str) -> str:
    s = unicodedata.normalize("NFKD", s).encode("ascii", "ignore").decode("ascii")
    s = re.sub(r"[^A-Za-z0-9._-]+", "_", s).strip("._")
    return s or "file"


# =========================
# 10) INTENTO FINANZAS (descarga + macro + guardado)
# =========================
def handle_finance_intent(text: str):
    # Si el prompt pide modelado, que lo maneje handle_ml_intent
    if re.search(r'\b(prophet|pronostica|forecast|xgboost|modelo|clasifica)\b', text, re.IGNORECASE):
        return None

    empresa, meses = extract_company_and_months(text)
    if not empresa and not meses:
        return None  # que lo responda el LLM

    if not meses:
        meses = 3  # default razonable

    ticker, resolved_name = resolve_ticker(empresa or "")
    if not ticker:
        return f"No pude encontrar el ticker de «{empresa or text}». Prueba con el símbolo directo (p. ej., AAPL)."

    # --- descarga original ---
    try:
        df, start, end = download_prices(ticker, meses)
    except Exception as e:
        return f"No pude descargar los datos de {ticker}: {e}"

    if df is None or df.empty:
        return f"No hay datos para {ticker} en los últimos {meses} meses."

    base = f"{slugify(ticker)}_{start.isoformat()}_{end.isoformat()}"
    fname_raw = f"precios_{base}_raw.csv"

    # (opcional) normalizar para guardar CSV "limpio"
    df_norm = normalize_ohlcv(df, ticker=ticker)
    df_to_save = df_norm.copy() if (df_norm is not None and not df_norm.empty) else df.copy()
    df_to_save.columns = list(map(str, df_to_save.columns))
    df_to_save.to_csv(fname_raw, index=True)

    df_imp, rep = impute_nans_prices(df)
    fname_imp = f"precios_{base}_imputed.csv"
    df_imp.to_csv(fname_imp, index=True)
    #MAMALON_PATH = "/content/drive/MyDrive/Hack-Nation 2025/Backend/Chatbot/codigo_mamalon.py"
    #ok = run_codigo_mamalon(MAMALON_PATH)
    #print("[DEBUG] codigo_mamalon.py ejecutado:", ok)
    # --- Aquí sigue tu flujo original ---
    try:
        df, start, end = download_prices(ticker, meses)
    except Exception as e:
        return f"No pude descargar los datos de {ticker}: {e}"

    if df is None or df.empty:
        return f"No hay datos para {ticker} en los últimos {meses} meses."

    base = f"{slugify(ticker)}_{start.isoformat()}_{end.isoformat()}"
    fname_raw = f"precios_{base}_raw.csv"

    df_to_save = df.copy()
    df_to_save.columns = list(map(str, df_to_save.columns))
    df_to_save.to_csv(fname_raw, index=True)

    df_imp, rep = impute_nans_prices(df)
    fname_imp = f"precios_{base}_imputed.csv"
    df_imp.to_csv(fname_imp, index=True)

    try:
        df, start, end = download_prices(ticker, meses)
    except Exception as e:
        return f"No pude descargar los datos de {ticker}: {e}"

    if df is None or df.empty:
        return f"No hay datos para {ticker} en los últimos {meses} meses."

    base = f"{slugify(ticker)}_{start.isoformat()}_{end.isoformat()}"
    fname_raw = f"precios_{base}_raw.csv"

    df_to_save = df.copy()
    df_to_save.columns = list(map(str, df_to_save.columns))
    df_to_save.to_csv(fname_raw, index=True)

    df_imp, rep = impute_nans_prices(df)
    fname_imp = f"precios_{base}_imputed.csv"
    df_imp.to_csv(fname_imp, index=True)

    country = get_company_country(ticker) or "United States"
    try:
        macro, vec = compute_macro_features(country)
    except Exception:
        macro, vec = None, None

    saved_macro = ""
    if vec is not None:
        npy_name = f"macro_features_{slugify(ticker)}.npy"
        csv_name = f"macro_features_{slugify(ticker)}.csv"
        np.save(npy_name, vec)
        pd.DataFrame([vec], columns=[
            "inflation_yoy","delta_inflation","gdp_real_growth",
            "delta_gdp_growth","unemployment","delta_unemployment","macro_score"
        ]).to_csv(csv_name, index=False)
        saved_macro = f"\nVector macro guardado: {npy_name} y {csv_name}"

    first_date, last_date = df.index.min().date(), df.index.max().date()
    rows = len(df)

    resumen = [
        f"Datos de {resolved_name or empresa or ticker} ({ticker})",
        f"Período: {first_date} → {last_date} (~{meses} meses)",
        f"Filas: {rows} (1d, auto_adjust=True)",
        f"CSV (raw): {fname_raw}",
        f"CSV (imputed): {fname_imp}",
        "",
        f"NaN imputados → antes: {rep.get('nan_totales_antes', 'N/D')} | después: {rep.get('nan_totales_despues', 'N/D')}",
        "Columnas numéricas: " + (", ".join(rep.get('columnas_numericas', [])) if rep.get('columnas_numericas') else "ninguna"),
        "",
        "Columnas finales: " + ", ".join(map(str, df_imp.columns))
    ]

    if macro:
        resumen += [
            "",
            f"País detectado: {macro['country']} (ISO2 {macro['iso2']})",
            f"Inflación {macro['infl_year']}: {macro['inflation_yoy'] if macro['inflation_yoy'] is not None else 'N/D'}% (Δ = {macro['delta_inflation'] if macro['delta_inflation'] is not None else 'N/D'} pp)",
            f"PIB real {macro['gdp_year']}: {macro['gdp_real_growth'] if macro['gdp_real_growth'] is not None else 'N/D'}% (Δ = {macro['delta_gdp_growth'] if macro['delta_gdp_growth'] is not None else 'N/D'} pp)",
            f"Desempleo {macro['unemp_year']}: {macro['unemployment'] if macro['unemployment'] is not None else 'N/D'}% (Δ = {macro['delta_unemployment'] if macro['delta_unemployment'] is not None else 'N/D'} pp)",
            f"Scores → infl: {macro['score_infl']:.2f}, pib: {macro['score_gdp']:.2f}, desempleo: {macro['score_unemp']:.2f}",
            f"Macro-score: {macro['macro_score']:.2f}",
            saved_macro
        ]

    return "\n".join(resumen)


# =========================
# 11) ML: FEATURES TÉCNICAS + XGBOOST
# =========================
def _calc_RSI(close: pd.Series, window=14):
    delta = close.diff()
    gain = delta.clip(lower=0).rolling(window=window).mean()
    loss = (-delta.clip(upper=0)).rolling(window=window).mean()
    RS = gain / loss
    return 100 - (100 / (1 + RS))

def _build_features(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out["Return"] = out["Close"].pct_change()
    out["Direction"] = (out["Return"] > 0).astype(int)

    out["RSI"] = _calc_RSI(out["Close"], 14)
    ema12 = out["Close"].ewm(span=12, adjust=False).mean()
    ema26 = out["Close"].ewm(span=26, adjust=False).mean()
    out["MACD"] = ema12 - ema26
    out["OBV"] = (np.sign(out["Close"].diff()).fillna(0) * out["Volume"]).cumsum()
    out["SMA_5"] = out["Close"].rolling(5).mean()
    out["SMA_10"] = out["Close"].rolling(10).mean()
    out["Spread_SMA"] = out["SMA_5"] - out["SMA_10"]
    high_low = out["High"] - out["Low"]
    high_close = (out["High"] - out["Close"].shift()).abs()
    low_close = (out["Low"] - out["Close"].shift()).abs()
    out["ATR"] = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1).rolling(14).mean()
    out["Momentum"] = out["Close"].diff(10)
    low_14 = out["Low"].rolling(14).min()
    high_14 = out["High"].rolling(14).max()
    out["Stochastic_K"] = 100 * (out["Close"] - low_14) / (high_14 - low_14)

    out = out.dropna()
    return out

def train_xgb_classifier(df_feat: pd.DataFrame):
    feats = ["RSI","MACD","OBV","Spread_SMA","ATR","Momentum","Stochastic_K"]
    X = df_feat[feats].values
    y = df_feat["Direction"].values

    scaler = MinMaxScaler()
    Xs = scaler.fit_transform(X)

    Xtr, Xte, ytr, yte = train_test_split(Xs, y, test_size=0.2, random_state=42, stratify=y)

    sm = SMOTE(random_state=42)
    Xtr_b, ytr_b = sm.fit_resample(Xtr, ytr)

    model = xgb.XGBClassifier(
        n_estimators=300,
        max_depth=5,
        learning_rate=0.05,
        subsample=0.8,
        colsample_bytree=0.8,
        reg_alpha=0.1,
        reg_lambda=1.0,
        eval_metric="logloss",
        random_state=42,
        n_jobs=-1
    )
    model.fit(Xtr_b, ytr_b)

    yhat = model.predict(Xte)
    yproba = model.predict_proba(Xte)[:,1]
    auc = roc_auc_score(yte, yproba)
    report = classification_report(yte, yhat, digits=3)
    cm = confusion_matrix(yte, yhat).tolist()

    metrics = {
        "auc": float(auc),
        "report": report,
        "confusion_matrix": cm
    }
    artifacts = {
        "scaler": scaler,
        "features_order": feats,
        "model": model
    }
    return artifacts, metrics


# =========================
# 12) PROPHET (mensual) + DERIVADAS
# =========================
def _prep_prophet_monthly(df: pd.DataFrame) -> pd.DataFrame:
    tmp = df.copy()
    tmp["Return"] = tmp["Close"].pct_change()

    m = pd.DataFrame({
        "y": tmp["Close"].resample("ME").mean()
    }).dropna()
    m["volume"] = tmp["Volume"].resample("ME").sum()
    m["range"] = (tmp["High"] - tmp["Low"]).resample("ME").mean()
    m["volatility"] = tmp["Return"].resample("ME").std()
    m = m.dropna()
    m["ds"] = m.index
    return m[["ds","y","volume","range","volatility"]]

def build_prophet():
    m = Prophet(
        daily_seasonality=False,
        yearly_seasonality=8,
        weekly_seasonality=False,
        changepoint_prior_scale=0.05,
        seasonality_mode="multiplicative",
        mcmc_samples=0,
        uncertainty_samples=300
    )
    m.add_seasonality(name="quarterly", period=91.25, fourier_order=3, prior_scale=5, mode="multiplicative")
    for r in ["volume","range","volatility"]:
        m.add_regressor(r)
    return m

def fit_predict_prophet(df_monthly: pd.DataFrame, months_ahead=12):
    m = build_prophet()
    m.fit(df_monthly.rename(columns={"ds":"ds","y":"y"}))
    futuro = m.make_future_dataframe(periods=months_ahead, freq="ME")
    for r in ["volume","range","volatility"]:
        futuro[r] = df_monthly[r].iloc[-1]
    fcst = m.predict(futuro)

    fig1 = m.plot(fcst)
    fig1.savefig("prophet_forecast.png", dpi=160, bbox_inches="tight")
    plt.close(fig1)

    fig2 = m.plot_components(fcst)
    fig2.savefig("prophet_components.png", dpi=160, bbox_inches="tight")
    plt.close(fig2)

    return m, fcst

def derivatives_summary(last_q_df: pd.DataFrame, first_q_fcst: pd.DataFrame):
    d_last = last_q_df["Close"].diff().mean()
    d_fc = first_q_fcst["yhat"].diff().mean()
    return float(d_last), float(d_fc)


# =========================
# 13) INTENTO DE MODELOS (XGBoost / Prophet)
# =========================
MODEL_RE = re.compile(
    r"(?:entrena|modelo|clasifica|pronostica|forecast|xgboost|prophet)\b",
    re.IGNORECASE
)

def handle_ml_intent(text: str):
    if not MODEL_RE.search(text):
        return None

    # Ticker
    m_tk = re.search(r"\b([A-Z]{1,6})(?:\b|[^a-zA-Z0-9])", text)
    ticker = m_tk.group(1) if m_tk else None
    if not ticker:
        empresa, _ = extract_company_and_months(text)
        if empresa:
            tk, _ = resolve_ticker(empresa)
            ticker = tk
    if not ticker:
        return "No identifiqué el ticker. Ejemplo: 'Pronostica con prophet AMZN 12 meses'."

    # >>> NUEVO: si es AMZN, ejecuta tu script en subproceso (no rompe el flujo)
    if ticker.upper() == "AMZN":
        ok = run_codigo_mamalon_subprocess("/content/codigo_mamalon.py")
        print(f"[DEBUG] Lanzamiento de codigo_mamalon.py (ML): {ok}")

    # Rango de fechas
    m_range = re.search(r"(\d{4}-\d{2}-\d{2})\s*(?:a|hasta|-|→|->)\s*(\d{4}-\d{2}-\d{2})", text)
    if m_range:
        start, end = m_range.group(1), m_range.group(2)
    else:
        end = date.today().isoformat()
        start = (date.today() - relativedelta(years=5)).isoformat()

    # Meses para forecast
    m_mo = re.search(r"(\d{1,2})\s*(?:mes(?:es)?)", text, re.IGNORECASE)
    months_ahead = int(m_mo.group(1)) if m_mo else 12

    # Descargar datos (buffer grande en meses)
    try:
        df_all, _s, _e = download_prices(ticker, months=200)
        if df_all is None or df_all.empty:
            return f"No pude descargar datos de {ticker}."
        df = df_all.loc[(df_all.index >= pd.to_datetime(start)) & (df_all.index <= pd.to_datetime(end))]
        if df.empty:
            return f"Sin datos de {ticker} entre {start} y {end}."
    except Exception as e:
        return f"Error bajando datos de {ticker}: {e}"

    # Imputación
    df_imp, _ = impute_nans_prices(df)
    df_imp.columns = [str(c) for c in df_imp.columns]

    # >>> NUEVO: normalizar columnas para evitar KeyError 'Close'
    base = normalize_ohlcv(df_imp, ticker=ticker)
    if base is None or base.empty or not set(["Open","High","Low","Close","Volume"]).issubset(base.columns):
        return f"No pude normalizar columnas OHLCV para {ticker}. Columnas vistas: {list(df_imp.columns)[:8]}"
    base = base.sort_index().dropna()

    wants_prophet = re.search(r"\bprophet|pronostica|forecast\b", text, re.IGNORECASE) is not None
    wants_xgb = re.search(r"\bxgboost|clasifica|modelo\b", text, re.IGNORECASE) is not None

    out = []

    # XGBoost
    if wants_xgb:
        feat = _build_features(base)
        art, metrics = train_xgb_classifier(feat)
        out += [
            f"XGBoost entrenado sobre {len(feat)} observaciones de {ticker} ({start} → {end}).",
            f"AUC en holdout: {metrics['auc']:.3f}",
            "Matriz de confusión (holdout): " + str(metrics["confusion_matrix"]),
            "Reporte de clasificación:\n" + metrics["report"],
        ]

    # Prophet + derivadas
    if wants_prophet:
        df_m = _prep_prophet_monthly(base)
        model, fcst = fit_predict_prophet(df_m, months_ahead=months_ahead)

        last_date = base.index.max()
        last_q = base[(base.index >= (last_date - pd.DateOffset(months=3))) & (base.index <= last_date)]
        first3 = fcst.sort_values("ds").head(3).copy()

        d_last, d_fc = derivatives_summary(last_q, first3)
        tail = fcst[["ds","yhat","yhat_lower","yhat_upper"]].tail(months_ahead)
        fcst_out = tail.to_string(index=False)

        out += [
            f"Prophet entrenado (mensual) con regresores. Guardado: prophet_forecast.png, prophet_components.png",
            f"Derivada promedio último trimestre observado: {d_last:.4f} USD/día",
            f"Derivada promedio primer trimestre pronosticado: {d_fc:.4f} por paso mensual",
            "",
            "Pronóstico (últimas filas):",
            fcst_out
        ]

    if not out:
        # Si dijo 'modelo' pero no especificó, corre ambos
        feat = _build_features(base)
        art, metrics = train_xgb_classifier(feat)
        df_m = _prep_prophet_monthly(base)
        model, fcst = fit_predict_prophet(df_m, months_ahead=months_ahead)
        last_date = base.index.max()
        last_q = base[(base.index >= (last_date - pd.DateOffset(months=3))) & (base.index <= last_date)]
        first3 = fcst.sort_values("ds").head(3).copy()
        d_last, d_fc = derivatives_summary(last_q, first3)
        out = [
            f"XGBoost AUC: {metrics['auc']:.3f}",
            f"Prophet listo. Archivos: prophet_forecast.png, prophet_components.png",
            f"Derivadas → observado: {d_last:.4f} / pronóstico: {d_fc:.4f}"
        ]

    return "\n".join(out)


# =========================
# 14) CLI PRINCIPAL
# =========================
def run_cli():
    model = make_model()
    chat = model.start_chat(history=[])
    print("Chatbot (Gemini + Yahoo Finance + Macro + XGBoost + Prophet). Escribe 'exit' para salir.")
    print("Ejemplos:")
    print("  - Dame los datos financieros de Microsoft de los últimos 3 meses")
    print("  - Pronostica con prophet AMZN 12 meses")
    print("  - Entrena xgboost de AMZN de 2018-01-01 a 2024-01-02")

    while True:
        try:
            user = input("Tú: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nAdiós")
            break

        if not user:
            continue
        if user.lower() in {"exit", "quit", "bye"}:
            print("Adiós")
            break

        # 1) Finanzas
        fin_resp = handle_finance_intent(user)
        if fin_resp:
            print("Bot:", fin_resp)
            continue

        # 2) Modelos
        ml_resp = handle_ml_intent(user)
        if ml_resp:
            print("Bot:", ml_resp)
            continue

        # 3) LLM
        try:
            reply = answer_with_llm(chat, user)
        except Exception as e:
            print(f"[Error LLM] {e}", file=sys.stderr)
            time.sleep(1.0)
            continue

        print("Bot:", reply)


# =========================
# 15) MAIN
# =========================
if __name__ == "__main__":
    # En Colab/Jupyter puedes llamar run_cli() para usar input interactivo,
    # o invocar directamente funciones si prefieres.
    run_cli()

"""Intento 3"""